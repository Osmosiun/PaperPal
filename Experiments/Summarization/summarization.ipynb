{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from groq import Groq\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "para1 = \"The Reddit dataset is a graph dataset from Reddit posts made in the month of September, 2014. The node label in this case is the community, or “subreddit”, that a post belongs to. 50 large communities have been sampled to build a post-to-post graph, connecting posts if the same user comments on both. In total this dataset contains 232,965 posts with an average degree of 492. The first 20 days are used for training and the remaining days for testing. For features, off-the-shelf 300-dimensional GloVe CommonCrawl word vectors are used.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key= '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',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating prompt template using langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define a PromptTemplate\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"para\"],\n",
    "    template=\"Summarize the paragraph: {para}. Answer should contain oly summary and nothing else.\",\n",
    ")\n",
    "\n",
    "# Step 2: Format the Prompt with Input Variables\n",
    "formatted_prompt = prompt_template.format(para=para1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Reddit dataset is a graph dataset of 232,965 posts from September 2014, with nodes labeled by subreddit community, connected if the same user comments on both posts, with 300-dimensional GloVe word vectors as features, and divided into 20 days for training and the rest for testing.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Execute the API call \n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": formatted_prompt,  # Use the formatted prompt here\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-70b-8192\",\n",
    ")\n",
    "\n",
    "# Step 4: Print the Response\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paperpal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
